---
layout: page
title: Cambridge Mindreading (CAM) Face-Voice Battery (Adult)
description:
tags: measures
---

Select Language (google translate):  

<div id="google_translate_element"></div><script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({pageLanguage: 'en', layout: google.translate.TranslateElement.InlineLayout.SIMPLE, gaTrack: true, gaId: 'UA-64320648-1'}, 'google_translate_element');
}
</script><script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>  

**Type of Measure:**  Per Golan, Baron-Cohen, and Hill (2006), adults with Asperger Syndrome have difficulty recognizing and understanding complex emotions, which impacts their ability communicate. The Cambridge Mindreading (CAM) Face-Voice Battery evaluates a selection of 20 emotion concepts, taken from an emotion taxonomy ((described in Baron-Cohen, Golan, Wheelwright, & Hill, 2004)[http://www.jkp.com/uk/mindreading/mainfeatures/]). The battery includes two tasks: emotion recognition in the face and emotion recognition in the voice. Each of these tasks has fifty questions, in which the participant is either watching 3–5 second silent clips of actors portraying an emotion (facial task), or listening to short sentences, spoken in a particular emotional intonation (vocal task). After watching the clip/listening to the voice recording, the participant is presented with four adjectives and is asked to choose the word that best describes how the person is feeling. There are four different scores that can be derived from the CAM: overall emotion regulation, facial emotion recognition, vocal emotion recognition, and concepts correctly recognized.     

**Target Population:** Adults with Aspergers Syndrome

**Measurement properties and previous use:** Reword: "Internal validity and convergent validity with the ‘Reading the Mind in the Eyes’’ task are discussed in Golan, O., Baron-Cohen, S. and Hill, J. (2006). 

In this study, we predicted that participants with AS would show deficits, relative to matched controls, on all 4 scores above. Another comparison we carried out was between the ability to recognise emotions from the face and
from the voice. Such a comparison is possible since
the CAM includes the same emotions in the facial
and vocal scale. We also tested for a group difference
on the face-voice comparison (i.e. a group by
modality interaction).
Lastly, we predicted that CAM scores would
positively correlate with the Revised ‘‘Reading the
Mind in the Eyes’’ test (Baron-Cohen et al., 2001)
and with a revised version of the ‘‘Reading the Mind
in the Voice’’ test (Golan, Baron-Cohen, Rutherford,
& Hill, submitted), which includes 4 foils for each
question instead of two in Rutherford et al.’s original task (Rutherford et al., 2002). The CAM scores were
also predicted to correlate negatively with scores of
the Autism Spectrum Quotient (AQ) (Baron-Cohen,
Wheelwright, Skinner, Martin, & Clubley, 2001). 

Item validation was conducted before carrying
out any group analysis. The data from the 21 adults
in the control group was first analysed as follows: An
item was considered valid if at least 11 out of 21
(>50%) of these participants selected the target word
and no more than 6 (<33%) selected any one of the
foils. Using these criteria, 5 of the concepts (3 from
level 6 and 2 from level 5) were excluded from the
battery. Eight other concepts had one invalid item
each, and these items were removed. In order to keep
the same number of items for all the concepts and to
keep the battery brief to administer, one item was
then randomly removed from each of the remaining
12 concepts, so that the final battery comprised 20
concepts with 5 items for each concept. The number
of concepts having 3 face and 2 voice items or 3 voice
and 2 face items were counterbalanced.

Results showed that individuals with Asperger
Syndrome (AS), when compared to general population
controls, had more difficulties in recognising
mental states from both faces and voices. In addition,
participants with AS recognised fewer mental state
concepts then controls. In twelve out of the twenty
emotions and mental states tested in the CAM, a
significantly lower number of participants with AS
successfully recognised the concept, compared to ageand
IQ-matched controls.
The fact that controls were matched on chronological,
verbal and nonverbal mental age, and the
lack of correlations between the CAM scores and
these factors, suggests the independence of complex
emotions and mental state recognition from verbal
and non-verbal ability. The strong negative correlation
of the CAM scores with the participants’ Autism
Spectrum Quotient (AQ) score (Baron-Cohen et al.,
2001) supports the relevance of emotion and mental
state recognition difficulties in high-functioning
adults with autism spectrum conditions. These
are important components of empathising (Baron-
Cohen, 2003). Despite their ability to recognise basic
emotions, such adults still find it hard to ‘‘mindread’’
complex mental states from faces and voices. The
relatively high correlation of the CAM facial and
vocal scales with the ‘‘Reading the Mind in the Eyes’’
(Baron-Cohen et al., 2001) and ‘‘Reading theMind in
the Voice-R’’ (Golan et al., submitted) tasks, respectively,
provides the task with important measures of
external validity. The CAM goes beyond these two
tasks by using motion in the facial scale items and by allowing the opportunity to analyse individual concepts. Its power levels show it is sensitive to group differences across all scales and scores."

**Languages:** English, Español, and Svensk 

**Authors and Citation:** Golan, O., Baron-Cohen, S., & Hill, J. (2006). The Cambridge mindreading (CAM) face-voice battery: Testing complex emotion recognition in adults with and without Asperger syndrome. Journal of autism and developmental disorders, 36(2), 169-183.

**Licence:** 

**Link to measure:** [Cambridge Mindreading (CAM) Face-Voice Battery (Adult)](https://www.autismresearchcentre.com/arc_tests/) 

Corrections or updates? [Let us know!](http://disabilitymeasures.org/contact)
